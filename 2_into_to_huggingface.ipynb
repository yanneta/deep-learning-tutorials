{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2802336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713781e",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "\n",
    "Sentiment analysis is an NLP task that classifies text as positive, negative, or neutral to determine its emotional tone, commonly used in social media monitoring, customer feedback analysis, and opinion mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3908f54-3928-408b-86f5-fa0050e3feaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_image_classification.ipynb  3_finetune_llms.ipynb\n",
      "2_into_to_huggingface.ipynb   4_image_segmentation.ipynb\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdef19",
   "metadata": {},
   "source": [
    "To get the sentiment data: <br>\n",
    "`wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz`\n",
    "\n",
    "To unzip run: <br>\n",
    "`! tar -xvf aclImdb_v1.tar.gz`\n",
    "\n",
    "This is a dataset for binary sentiment classification (positive or negative). The training data consists of 25,000 movie reviews for training, and 25,000 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38161d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n"
     ]
    }
   ],
   "source": [
    "! ls ~/data/aclImdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "424f8b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    f = open(path, \"r\")\n",
    "    return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b22d0553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_path = Path(\"~/data/aclImdb/test\")\n",
    "test_path = test_path.expanduser()\n",
    "pos_paths = [f for f in (test_path/\"pos\").iterdir()]\n",
    "neg_paths = [f for f in (test_path/\"neg\").iterdir()]\n",
    "data_pos = [read_file(pos_paths[i]) for i in range(10)]\n",
    "data_neg = [read_file(neg_paths[i]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2916ae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably will\n",
      "not like this movie. Most of these movies may not have the best plots or best actors but I enjoy\n",
      "these kinds of movies for what they are. This movie is much better than any of the movies the other\n",
      "action guys (Segal and Dolph) have thought about putting out the past few years. Van Damme is good\n",
      "in the movie, the movie is only worth watching to Van Damme fans. It is not as good as Wake of Death\n",
      "(which i highly recommend to anyone of likes Van Damme) or In hell but, in my opinion it's worth\n",
      "watching. It has the same type of feel to it as Nowhere to Run. Good fun stuff!\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "text = read_file(neg_paths[4])\n",
    "\n",
    "wrapped_text = textwrap.fill(text, width=100)  \n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eadc9b",
   "metadata": {},
   "source": [
    "Here is a [link](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads&search=sentiment) to models that are useful for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a6cf408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4bbd724",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba6ff7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997010827064514},\n",
       " {'label': 'POSITIVE', 'score': 0.9957257509231567},\n",
       " {'label': 'POSITIVE', 'score': 0.9472860097885132},\n",
       " {'label': 'POSITIVE', 'score': 0.8518150448799133},\n",
       " {'label': 'POSITIVE', 'score': 0.9996123909950256},\n",
       " {'label': 'POSITIVE', 'score': 0.9388156533241272},\n",
       " {'label': 'POSITIVE', 'score': 0.9882730841636658},\n",
       " {'label': 'POSITIVE', 'score': 0.9941344857215881},\n",
       " {'label': 'POSITIVE', 'score': 0.6735564470291138},\n",
       " {'label': 'POSITIVE', 'score': 0.952999472618103}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(data_pos, max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67379cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.999616265296936},\n",
       " {'label': 'NEGATIVE', 'score': 0.6170626282691956},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997100234031677},\n",
       " {'label': 'NEGATIVE', 'score': 0.995756208896637},\n",
       " {'label': 'POSITIVE', 'score': 0.996307373046875},\n",
       " {'label': 'NEGATIVE', 'score': 0.9966711401939392},\n",
       " {'label': 'NEGATIVE', 'score': 0.958416759967804},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994093179702759},\n",
       " {'label': 'NEGATIVE', 'score': 0.9996923208236694},\n",
       " {'label': 'NEGATIVE', 'score': 0.99977046251297}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(data_neg, max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018f3f1",
   "metadata": {},
   "source": [
    "Here we specify the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f65c1da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_path = \"siebert/sentiment-roberta-large-english\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb5f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.998914361000061},\n",
       " {'label': 'POSITIVE', 'score': 0.9988763928413391},\n",
       " {'label': 'POSITIVE', 'score': 0.9987799525260925},\n",
       " {'label': 'POSITIVE', 'score': 0.9989105463027954},\n",
       " {'label': 'POSITIVE', 'score': 0.9988929629325867},\n",
       " {'label': 'POSITIVE', 'score': 0.9843221306800842},\n",
       " {'label': 'POSITIVE', 'score': 0.9988069534301758},\n",
       " {'label': 'POSITIVE', 'score': 0.9989105463027954},\n",
       " {'label': 'POSITIVE', 'score': 0.9988324046134949},\n",
       " {'label': 'POSITIVE', 'score': 0.9989055395126343}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_task(data1, max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b2c59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9995086193084717},\n",
       " {'label': 'POSITIVE', 'score': 0.9988320469856262},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995156526565552},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995115995407104},\n",
       " {'label': 'POSITIVE', 'score': 0.998916506767273},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995063543319702},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991637468338013},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995145797729492},\n",
       " {'label': 'NEGATIVE', 'score': 0.999512791633606},\n",
       " {'label': 'NEGATIVE', 'score': 0.9995163679122925}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_task(data2, max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd7e85",
   "metadata": {},
   "source": [
    "## Text summarization\n",
    "Text summarization is a natural language processing task aimed at condensing the content of a given text while retaining its key information and meaning. This task is crucial for information retrieval, document organization, and content consumption in various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722634c",
   "metadata": {},
   "source": [
    "You can download a summarization dataset from [here](\n",
    "https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fad5f792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"~/data/cnn_dailymail/test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86151c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92c514c913c0bdfe25341af9fd72b29db544099b</td>\n",
       "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
       "      <td>Experts question if  packed out planes are put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003841c7dc0e7c5b1a248f9cd536d727f27a45a</td>\n",
       "      <td>A drunk teenage boy had to be rescued by secur...</td>\n",
       "      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91b7d2311527f5c2b63a65ca98d21d9c92485149</td>\n",
       "      <td>Dougie Freedman is on the verge of agreeing a ...</td>\n",
       "      <td>Nottingham Forest are close to extending Dougi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caabf9cbdf96eb1410295a673e953d304391bfbb</td>\n",
       "      <td>Liverpool target Neto is also wanted by PSG an...</td>\n",
       "      <td>Fiorentina goalkeeper Neto has been linked wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3da746a7d9afcaa659088c8366ef6347fe6b53ea</td>\n",
       "      <td>Bruce Jenner will break his silence in a two-h...</td>\n",
       "      <td>Tell-all interview with the reality TV star, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
       "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
       "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
       "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
       "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
       "\n",
       "                                             article  \\\n",
       "0  Ever noticed how plane seats appear to be gett...   \n",
       "1  A drunk teenage boy had to be rescued by secur...   \n",
       "2  Dougie Freedman is on the verge of agreeing a ...   \n",
       "3  Liverpool target Neto is also wanted by PSG an...   \n",
       "4  Bruce Jenner will break his silence in a two-h...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Experts question if  packed out planes are put...  \n",
       "1  Drunk teenage boy climbed into lion enclosure ...  \n",
       "2  Nottingham Forest are close to extending Dougi...  \n",
       "3  Fiorentina goalkeeper Neto has been linked wit...  \n",
       "4  Tell-all interview with the reality TV star, 6...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d3a7cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of\n",
      "people taking to the skies, some experts are questioning if having such packed out planes is putting\n",
      "passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's\n",
      "putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on\n",
      "planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by\n",
      "the Department of Transportation said at a public hearing that while the government is happy to set\n",
      "standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans.\n",
      "'In a world where animals have more rights to space and food than humans,' said Charlie Leocha,\n",
      "consumer representative on the committee. 'It is time that the DOT and FAA take a stand for humane\n",
      "treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for\n",
      "space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use\n",
      "planes with a 31 inch pitch, a standard which on some airlines has decreased . Many economy seats on\n",
      "United Airlines have 30 inches of room, while some airlines offer as little as 28 inches . Cynthia\n",
      "Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts\n",
      "tests on how quickly passengers can leave a plane. But these tests are conducted using planes with\n",
      "31 inches between each row of seats, a standard which on some airlines has decreased, reported the\n",
      "Detroit News. The distance between two seats from one point on a seat to the same point on the seat\n",
      "behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some\n",
      "fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between\n",
      "29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British\n",
      "Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch\n",
      "is 28 inches, and Virgin Atlantic's is 30-31.\n"
     ]
    }
   ],
   "source": [
    "text = df.iloc[0].article\n",
    "wrapped_text = textwrap.fill(text, width=100)  \n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2faa99de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experts question if  packed out planes are putting\n",
      "passengers at risk . U.S consumer advisory group\n",
      "says minimum space must be stipulated . Safety\n",
      "tests conducted on planes with more leg room than\n",
      "airlines offer .\n"
     ]
    }
   ],
   "source": [
    "text = df.iloc[0].highlights\n",
    "wrapped_text = textwrap.fill(text, width=50)  \n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc2f8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = df.iloc[0].article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f578c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some experts say that the shrinking space on\n",
      "aeroplanes is not only uncomfortable - it's\n",
      "putting our health and safety in danger . this\n",
      "week, a consumer advisory group set up by the\n",
      "department of transportation said at a public\n",
      "hearing that while the government is happy to set\n",
      "standards for animals flying on planes, it doesn't\n",
      "stipulate a minimum amount of space for humans .\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"t5-base\")\n",
    "\n",
    "summary = summarizer(input_text, max_length=120, min_length=50, length_penalty=2.0,\n",
    "                     num_beams=4, early_stopping=True, truncation=True)\n",
    "\n",
    "text = summary[0]['summary_text']\n",
    "wrapped_text = textwrap.fill(text, width=50)  \n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f566dc6f-ee9d-479b-9f38-63d0490758d2",
   "metadata": {},
   "source": [
    "### a different model\n",
    "Let's try `google/flan-t5-base` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca6ffc2a-ad95-47c6-ad19-a8a1841fb6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experts say the shrinking space on aeroplanes is\n",
      "not only uncomfortable - it's putting our health\n",
      "and safety in danger. U.S consumer advisory group\n",
      "set up by the Department of Transportation said at\n",
      "a public hearing that while the government is\n",
      "happy to set standards for animals flying on\n",
      "planes, it doesn't stipulate a minimum amount of\n",
      "space for humans.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"google/flan-t5-base\",\n",
    "                      tokenizer=\"google/flan-t5-base\")\n",
    "\n",
    "input_text = df.iloc[0].article\n",
    "\n",
    "# Generate summary\n",
    "summary = summarizer(input_text, max_length=150, min_length=50, length_penalty=2.0,\n",
    "                     num_beams=8, early_stopping=True, truncation=True)\n",
    "\n",
    "\n",
    "text = summary[0]['summary_text']\n",
    "wrapped_text = textwrap.fill(text, width=50)  \n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa45b9-8265-4d14-9e4f-a1e42584c553",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Zero shot classification\n",
    "Zero-Shot Classification is a task in natural language processing where a model is trained to predict a class that it did not encounter during its training phase. This method uses  a pre-trained language model and can be considered an instance of transfer learning, which refers to using a model trained for one task in a different application than its original purpose. This approach is particularly useful when the amount of labeled data is limited. <br>\n",
    "In zero-shot classification, the model is provided with a prompt and a sequence of text that describes the desired action in natural language. This differs from single or few-shot classification, which includes one or a few examples of the selected task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6cf90c-3280-42fd-bf67-4262abe0b5f5",
   "metadata": {},
   "source": [
    "Let's consider this news category dataset https://www.kaggle.com/datasets/rmisra/news-category-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b136c797-2704-4eb5-8b2e-bde61f526ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('~/data/News_Category_Dataset_v3.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1858abe4-b280-4751-bae7-e18324711c59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "        date  \n",
       "0 2022-09-23  \n",
       "1 2022-09-23  \n",
       "2 2022-09-23  \n",
       "3 2022-09-23  \n",
       "4 2022-09-22  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da9af568-d7e2-4722-9d66-3951beabaaf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['U.S. NEWS', 'COMEDY', 'PARENTING', 'WORLD NEWS', 'CULTURE & ARTS',\n",
       "       'TECH', 'SPORTS', 'ENTERTAINMENT', 'POLITICS', 'WEIRD NEWS',\n",
       "       'ENVIRONMENT', 'EDUCATION', 'CRIME', 'SCIENCE', 'WELLNESS',\n",
       "       'BUSINESS', 'STYLE & BEAUTY', 'FOOD & DRINK', 'MEDIA',\n",
       "       'QUEER VOICES', 'HOME & LIVING', 'WOMEN', 'BLACK VOICES', 'TRAVEL',\n",
       "       'MONEY', 'RELIGION', 'LATINO VOICES', 'IMPACT', 'WEDDINGS',\n",
       "       'COLLEGE', 'PARENTS', 'ARTS & CULTURE', 'STYLE', 'GREEN', 'TASTE',\n",
       "       'HEALTHY LIVING', 'THE WORLDPOST', 'GOOD NEWS', 'WORLDPOST',\n",
       "       'FIFTY', 'ARTS', 'DIVORCE'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e4e303f-070b-441b-8377-5be30c11817d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8bfd237-4e1d-4d5f-afd5-a4d5e95f7152",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u.s. news', 'comedy', 'parenting', 'world news']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = ['U.S. NEWS', 'COMEDY', 'PARENTING', 'WORLD NEWS']\n",
    "cats = [x.lower() for x in cats]\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d15e43a2-9566-4cf7-80a1-9ecd15a32a63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "text = df.iloc[i].short_description\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f91a04ba-89f7-477d-8354-90a921cc5384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "text = df.iloc[0].short_description\n",
    "pipe = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "results = pipe(text, candidate_labels=['u.s. news', 'comedy', 'parenting', 'world news', 'tech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c31cea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u.s. news 0.52\n",
      "world news 0.39\n",
      "parenting 0.05\n",
      "comedy 0.03\n"
     ]
    }
   ],
   "source": [
    "for l,s in zip(results[\"labels\"], results[\"scores\"]):\n",
    "    print(\"%s %.2f\" % (l, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d72e6d3d-c91d-4bee-827e-61be4e24a083",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual: U.S. NEWS predicted: u.s. news\n",
      "actual: U.S. NEWS predicted: u.s. news\n",
      "actual: COMEDY predicted: parenting\n",
      "actual: PARENTING predicted: parenting\n",
      "actual: U.S. NEWS predicted: world news\n",
      "actual: U.S. NEWS predicted: tech\n",
      "actual: U.S. NEWS predicted: u.s. news\n",
      "actual: WORLD NEWS predicted: u.s. news\n",
      "actual: CULTURE & ARTS predicted: u.s. news\n",
      "actual: WORLD NEWS predicted: world news\n",
      "actual: WORLD NEWS predicted: world news\n",
      "actual: WORLD NEWS predicted: world news\n",
      "actual: WORLD NEWS predicted: world news\n",
      "actual: TECH predicted: u.s. news\n",
      "actual: U.S. NEWS predicted: u.s. news\n",
      "actual: WORLD NEWS predicted: tech\n",
      "actual: CULTURE & ARTS predicted: comedy\n",
      "actual: SPORTS predicted: u.s. news\n",
      "actual: WORLD NEWS predicted: world news\n",
      "actual: WORLD NEWS predicted: tech\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    text = df.iloc[i].short_description\n",
    "    results = pipe(text, candidate_labels=['u.s. news', 'comedy', 'parenting', 'world news', 'tech'])\n",
    "    print(\"actual:\", df.iloc[i].category, \"predicted:\", results['labels'][0])\n",
    "    #print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47828edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Accidentally put grown-up toothpaste on my\n",
      "toddler’s toothbrush and he screamed like I was\n",
      "cleaning his teeth with a Carolina Reaper dipped\n",
      "in Tabasco sauce.\"\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "text = df.iloc[i].short_description\n",
    "wrapped_text = textwrap.fill(text, width=50)  \n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff0c68",
   "metadata": {},
   "source": [
    "## Extracting questions and answers from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e338e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install --upgrade vllm\n",
    "#! pip install --upgrade huggingface_hub\n",
    "#! pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3cff2643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model= MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d725179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_pairs(text):\n",
    "    \"\"\"Uses a LLaMA model to generate Q&A pairs from text.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Given the following text:\n",
    "\n",
    "    {text}\n",
    "\n",
    "    Step 1: Identify key facts and their answers.\n",
    "    Step 2: Generate multiple question-answer pairs from the given text.\n",
    "\n",
    "    Provide output in the format:\n",
    "    Q1: [question] A1: [answer]\n",
    "    Q2: [question] A2: [answer]\n",
    "    ...\n",
    "    \"\"\"\n",
    "\n",
    "    response = pipe(prompt, max_new_tokens=200, temperature=0.7, do_sample=True)\n",
    "\n",
    "    generated_text = response[0]['generated_text']\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "849b7cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "text = \"The Eiffel Tower is in Paris. It was completed in 1889 and stands 330 meters tall.\"\n",
    "generated_text = generate_qa_pairs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "993bef79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is in Paris. It was completed in\n",
      "1889 and stands 330 meters tall.\n"
     ]
    }
   ],
   "source": [
    "wrapped_text = textwrap.fill(text, width=50)  \n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5142b14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['    Q2: [question] A2: [answer]',\n",
       " '    ...',\n",
       " '     Q10: [question] A10: [answer]',\n",
       " '',\n",
       " '    Example output:',\n",
       " '    Q1: What is the height of the Eiffel Tower? ',\n",
       " '    A1: 330 meters',\n",
       " '    Q2: Where is the Eiffel Tower located? ',\n",
       " '    A2: Paris',\n",
       " '   ...',\n",
       " '    Q10: What year was the Eiffel Tower completed? ',\n",
       " '    A10: 1889',\n",
       " '',\n",
       " '    Eiffel Tower Facts:',\n",
       " '    Q1: What is the height of the Eiffel Tower?',\n",
       " '    A1: 330 meters',\n",
       " '    Q2: Where is the Eiffel Tower located?',\n",
       " '    A2: Paris',\n",
       " '    Q3: How tall is the Eiffel Tower?',\n",
       " '    A3: 330 meters']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text.split(\"\\n\")[10:30]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
